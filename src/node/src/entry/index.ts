import { createLLM } from "@src/libs/llm";
import { LLMConfig } from "@src/libs/llm/interfaces/LLMProvider";
import {
  MCPServerName,
  Message,
  MessageData,
  ModelSettings,
} from '@agent-infra/shared';
import { v4 as uuid } from 'uuid';
import { AgentFlow } from "./agent-flow";
import { useAgentFlow } from "@src/hooks/use-agent-flow";

const config: LLMConfig = {
  // model: "gpt-4o-mini",
  model: "deepseek",
  apiKey: process.env.OPENAI_API_KEY,
};

async function main () {

  const launchAgentFlow = useAgentFlow();

  launchAgentFlow(
    'å¸®æˆ‘æµè§ˆå™¨æ‰“å¼€bossç›´è˜å¹¶ç™»å½•åä¸‹è½½å·²æ²Ÿé€šäººé€‰å‰ä¸‰ä»½ç®€å†å¹¶è¿›è¡Œä¸‹è½½ååˆ†æ',
    []
  )

  // const agentFlowId = uuid();
  //   // ğŸ”¥ åˆ›å»º AgentFlow å®ä¾‹
  // const agentFlow = new AgentFlow({
  //   chatUtils, setEvents, setEventId, setAgentStatusTip,
  //   setPlanTasks, setShowCanvas, agentFlowId,
  //   request: { inputText, inputFiles }
  // });
  // // ğŸ”¥ è¿è¡Œ Agent æµç¨‹
  // await agentFlow.run();
  // const llm = createLLM(config);

  // const response = await llm.askTool({
  //   messages: [
  //     // Message.userMessage('What model are you using now?')
  //     // Message.userMessage('å¸®æˆ‘æ‰“å¼€bossç›´è˜å¹¶ç™»å½•')
  //     Message.userMessage('å¸®æˆ‘æµè§ˆå™¨æ‰“å¼€bossç›´è˜å¹¶ç™»å½•åä¸‹è½½å·²æ²Ÿé€šäººé€‰å‰ä¸‰ä»½ç®€å†å¹¶è¿›è¡Œä¸‹è½½ååˆ†æ')
  //   ],
  //   mcpServerKeys: ['browser', 'filesystem', 'commands'],
  //   requestId: 'test',
  //   toolChoice: 'required',
  //   tools: [
  //     // {
  //     //   type: 'function',
  //     //   function: {
  //     //     name: 'get_model_name',
  //     //     description: 'Get the name of the current model',
  //     //     parameters: {
  //     //       type: 'object',
  //     //       properties: {
  //     //         model: {
  //     //           type: 'string',
  //     //           description: 'The name of the model',
  //     //         },
  //     //       },
  //     //     },
  //     //   },
  //     // },
  //   ],
  // });

  // console.log(response);

}

main()